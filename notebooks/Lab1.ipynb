{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8jx134dakEm"
   },
   "source": [
    "# Introduction to Neural Networks\n",
    "\n",
    "In this lab, you will have your first contact with Neural Networks, and neural network training. We will use Pytorch to quickly deploy and train neural networks in different types of data, assess their performance and interpret their results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v7_tMzMAdxf6"
   },
   "source": [
    "## Preparation\n",
    "\n",
    "To create our first neural network model, we are going to load the Pytorch library, which contains many of the necessary utilities to deploy and train neural network models. We also import `numpy`, a library that is useful for some numerical computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aWvGUgnDabis",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XqUXs65eeNP"
   },
   "source": [
    "The most basic `Pytorch` datatype is the tensor, which you can think of as a more general version of a matrix. `Pytorch` tensors are built to facilitate the computation of gradients, which will be useful when we train our neural network models.\n",
    "\n",
    "Let us start by creating a simple random tensor and check some of its attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1vvSWjWQeZYo",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8345, 0.7270, 0.7358, 0.4049],\n",
      "        [0.2613, 0.0529, 0.5568, 0.9982],\n",
      "        [0.4074, 0.9245, 0.7670, 0.0882]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(3, 4) # Create a 3 x 4 tensor with random numbers\n",
    "\n",
    "# Let's check the contents of t\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hGEOzAGqfDDl",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device used to store tensor: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Let's now check some properties of t\n",
    "print('Shape of tensor:', t.shape)\n",
    "print('Datatype of tensor:', t.dtype)\n",
    "print('Device used to store tensor:', t.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "nzXUvb7pfTKc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used to store tensor: cuda:0\n",
      "Device name: Quadro RTX 3000\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Let's now move our tensor to a GPU, if one is available\n",
    "if torch.cuda.is_available():\n",
    "    t = t.to('cuda')\n",
    "    print('Device used to store tensor:', t.device)\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    print('No GPU available.')\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7oECt6pf5by"
   },
   "source": [
    "## Differentiation with `autograd`\n",
    "\n",
    "Let's look at how Pytorch helps with keeping track of gradients. To that purpose, we will create two tensors, perform some operations on them, and check how these operations are tracked for the purpose of computing the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Ub3LJ0ZPffqL",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: tensor([2., 3.], device='cuda:0', grad_fn=<ToCopyBackward0>)\n",
      "b: tensor([6., 4.], device='cuda:0', grad_fn=<ToCopyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# We create two tensors with two elements each, and activate gradient tracking\n",
    "a = torch.tensor([2., 3.], requires_grad=True).to(device)\n",
    "b = torch.tensor([6., 4.], requires_grad=True).to(device)\n",
    "\n",
    "print('a:', a)\n",
    "print('b:', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_eOFNLnMgnGn"
   },
   "source": [
    "Let's perform some computation using `a` and `b`. In particular, let us compute\n",
    "\n",
    "$$c=3a^3-b^2$$\n",
    "\n",
    "where the powers are computed elementwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "2Y7hpKiOgliV",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c = tensor([-12.,  65.], device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "c = 3 * a ** 3 - b ** 2\n",
    "print('c =', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "878ZNEHThdj8"
   },
   "source": [
    "We have that:\n",
    "\n",
    "$$\\frac{\\partial c}{\\partial a}=9a^2,$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\frac{\\partial c}{\\partial b}=-2b.$$\n",
    "\n",
    "When we call the method `.backward()` on `c`, `Autograd` calculates these gradients and stores them in the respective tensors' `.grad` attribute. For example, we can compute the sum of the elements in `c` and then backpropagate the gradient, to have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qc47I_rmg2zO",
    "tags": []
   },
   "outputs": [],
   "source": [
    "c.sum().backward()\n",
    "\n",
    "grada = a.grad\n",
    "gradb = b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "JrInhnERiQam",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 * a ** 2 = tensor([36., 81.], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "grad_a = None\n",
      "\n",
      "-2b = tensor([-12.,  -8.], device='cuda:0', grad_fn=<MulBackward0>)\n",
      "grad_b = None\n"
     ]
    }
   ],
   "source": [
    "print('9 * a ** 2 =', 9 * a ** 2)\n",
    "print('grad_a =', grada)\n",
    "\n",
    "print('\\n-2b =', -2 * b)\n",
    "print('grad_b =', gradb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XVaa5lYjQ0R"
   },
   "source": [
    "## Neural networks\n",
    "\n",
    "We can now implement our first neural network. We will use the neural network to classify pieces of clothing in the well known Fashion-MNIST dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5cKRCtMrmzA7"
   },
   "source": [
    "### Data\n",
    "\n",
    "We start by loading the data to be used, for which we use the `torchvision` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Ump4DMofjFsy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The library torchvision will be used to load the data\n",
    "import torchvision\n",
    "\n",
    "# The transforms module is used to convert the data into adequate Pytorch\n",
    "# tensors.\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "1Ys4Klpzkrs5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We import data for training and testing separately\n",
    "train_set = torchvision.datasets.FashionMNIST(root=\"./\", download=True,\n",
    "                                              train=True,\n",
    "                                              transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(root=\"./\", download=True, \n",
    "                                              train=False,\n",
    "                                              transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IYJqeU7k6jj"
   },
   "source": [
    "To facilitate the manipulation of the data, we create a **data loader**: an object that is used to get batches of data from the dataset during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "yLwHxK4Oky8b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(train_set, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTtgUHO2lTEA"
   },
   "source": [
    "Let's visualize some of the samples in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "z-IA6hhAlR9n",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image tensor: torch.Size([10, 1, 28, 28])\n",
      "class labels: tensor([0, 3, 0, 7, 9, 4, 4, 6, 2, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4f39012800>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import plotting utilities\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get a sample from our dataloader. \n",
    "# The sample consists of a batch of images and corresponding labels.\n",
    "images, labels = next(iter(data_loader))\n",
    "\n",
    "# To plot the sample, we create a grid\n",
    "plt.figure(figsize=(15, 10))\n",
    "grid = torchvision.utils.make_grid(nrow=20, tensor=images)\n",
    "print('Image tensor:', images.shape)\n",
    "print('class labels:', labels)\n",
    "\n",
    "# Plot the samples\n",
    "plt.imshow(np.transpose(grid, axes=(1,2,0)), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OADzvTn-m7cz"
   },
   "source": [
    "Let's decode the previous output. The images in the sample are stored in a single tensor with dimensions 10 &times; 1 &times; 28 &times; 28. What this means is that the sample contains:\n",
    "\n",
    "* 10 images;\n",
    "* Each image has a single channel, since these are black & white images. Colored images would have 3 channels (RGB);\n",
    "* Each image is 28 &times; 28 pixels.\n",
    "\n",
    "The labels are encoded as numbers. For example, 5 stands for \"sandal\", 8 for \"bag\", 7 for \"sneaker\", etc. The complete correspondence is summarized in the next table.\n",
    "\n",
    "| Label   |  0  |  1  |  2  |  3  |  4  |  5  |  6  |  7  |  8  |  9  | \n",
    "| ------- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | \n",
    "| Object  | T-shirt | Trousers | Pull-over | Dress | Coat | Sandal | Shirt | Sneaker | Bag | Boot |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "9oArL5vRt69R",
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABELS = ('T-shirt', 'Trousers', 'Pull-over', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Boot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aC69Z6rzodTs"
   },
   "source": [
    "### Creating a neural network\n",
    "\n",
    "We will now create a simple neural network. We use the `nn` module of Pytorch and create a new class corresponding to the neural network. In this class, we should specify the `__init__` method, and the `forward` method, which computes the output for a given input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Vlvj_yTpmXW7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# We create a new class \"FeedForwardNetwork\" from nn.Module\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Call the super class constructor\n",
    "        super().__init__()\n",
    "\n",
    "        # Our network will have a single hidden layer with 100 units\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Flatten(),        # Convert 28 x 28 images into a flat tensor\n",
    "            nn.Linear(784, 100), # 28 x 28 = 784 inputs; 100 outputs\n",
    "            nn.ReLU(),           # Add ReLU activation\n",
    "            nn.Linear(100, 10)   # 100 inputs; 10 outputs (10 classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # implements the forward method (flow of tensors)\n",
    "        # Given input x, we just run x through the layers in the network\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6nrXC_1tcMI"
   },
   "source": [
    "We can see how the (untrained) network classifies the examples in the sample. As expected, the classification is completely meaningless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "X8Rh44l3ru9K",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 0:\n",
      "\tEstimated label: Shirt\n",
      "\tCorrect label: T-shirt\n",
      "\n",
      "Image 1:\n",
      "\tEstimated label: Shirt\n",
      "\tCorrect label: Dress\n",
      "\n",
      "Image 2:\n",
      "\tEstimated label: Shirt\n",
      "\tCorrect label: T-shirt\n",
      "\n",
      "Image 3:\n",
      "\tEstimated label: Shirt\n",
      "\tCorrect label: Sneaker\n",
      "\n",
      "Image 4:\n",
      "\tEstimated label: Shirt\n",
      "\tCorrect label: Boot\n",
      "\n",
      "Image 5:\n",
      "\tEstimated label: Shirt\n",
      "\tCorrect label: Coat\n",
      "\n",
      "Image 6:\n",
      "\tEstimated label: Shirt\n",
      "\tCorrect label: Coat\n",
      "\n",
      "Image 7:\n",
      "\tEstimated label: Shirt\n",
      "\tCorrect label: Shirt\n",
      "\n",
      "Image 8:\n",
      "\tEstimated label: Shirt\n",
      "\tCorrect label: Pull-over\n",
      "\n",
      "Image 9:\n",
      "\tEstimated label: Shirt\n",
      "\tCorrect label: Sandal\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the network\n",
    "net = FeedForwardNetwork().to(device)\n",
    "\n",
    "# Run the sample through the network\n",
    "output = net(images.to(device))\n",
    "\n",
    "# Let's check the classification\n",
    "for i in range(output.shape[0]):\n",
    "    y_est = torch.argmax(output[i, :])\n",
    "    y_opt = labels[i]\n",
    "    print('\\nImage %i:' % i)\n",
    "    print('\\tEstimated label:', LABELS[y_est])\n",
    "    print('\\tCorrect label:', LABELS[y_opt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGQTjBUduzYE"
   },
   "source": [
    "## Training the network\n",
    "\n",
    "Let us now train the network we just created. The first thing to do is to specify how to measure the performance of our network, and then optimize the parameters of our network with respect to the defined performance measure. \n",
    "\n",
    "As performance criterion, we will use the _cross-entropy loss_, which measures the negative log-likelihood of the data according to the neural network. By adjusting the parameters of the network to minimize this loss, we are implicitly optimizing the network to make the observed labels in the dataset as likely as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "sYoTjlENsWNe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2qhlMaOyvw2"
   },
   "source": [
    "We now proceed with the training of the network. We will train the network for 20 epochs using stochastic gradient descent with a learning rate of 0.01. To fetch the data from the dataset we use the previously created data loader. However, since we've already extracted a sample (batch), we start by resetting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "J9mDwlPUytIk",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 0\n",
      "Training loss: 1.3728\n",
      "Training epoch: 1\n",
      "Training loss: 0.7749\n",
      "Training epoch: 2\n",
      "Training loss: 0.6550\n",
      "Training epoch: 3\n",
      "Training loss: 0.5927\n",
      "Training epoch: 4\n",
      "Training loss: 0.5541\n",
      "Training epoch: 5\n",
      "Training loss: 0.5278\n",
      "Training epoch: 6\n",
      "Training loss: 0.5078\n",
      "Training epoch: 7\n",
      "Training loss: 0.4934\n",
      "Training epoch: 8\n",
      "Training loss: 0.4814\n",
      "Training epoch: 9\n",
      "Training loss: 0.4715\n",
      "Training epoch: 10\n",
      "Training loss: 0.4633\n",
      "Training epoch: 11\n",
      "Training loss: 0.4563\n",
      "Training epoch: 12\n",
      "Training loss: 0.4497\n",
      "Training epoch: 13\n",
      "Training loss: 0.4442\n",
      "Training epoch: 14\n",
      "Training loss: 0.4389\n",
      "Training epoch: 15\n",
      "Training loss: 0.4346\n",
      "Training epoch: 16\n",
      "Training loss: 0.4305\n",
      "Training epoch: 17\n",
      "Training loss: 0.4265\n",
      "Training epoch: 18\n",
      "Training loss: 0.4226\n",
      "Training epoch: 19\n",
      "Training loss: 0.4192\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# Define the optimizer. We indicate:\n",
    "#   - What is being optimized (the parameters of the network)\n",
    "#   - The learning rate \n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
    "\n",
    "# Reset data loader\n",
    "iter(data_loader)\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    print('Training epoch:', ep)\n",
    "\n",
    "    # Keep track of the loss during training\n",
    "    train_loss = []\n",
    "\n",
    "    # We use our data loader to fetch batches from our dataset\n",
    "    for Xbatch, ybatch in data_loader:\n",
    "        Xbatch, ybatch = Xbatch.to(device), ybatch.to(device)\n",
    "        # We first zero-out the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute output\n",
    "        output = net(Xbatch)\n",
    "\n",
    "        # Get loss\n",
    "        l = loss(output, ybatch)\n",
    "\n",
    "        # Compute gradients\n",
    "        l.backward()\n",
    "\n",
    "        # Perform optimization step\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss.append(l)\n",
    "\n",
    "    print('Training loss: %.4f' % torch.tensor(train_loss).mean().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1uj1KdL9oNE"
   },
   "source": [
    "Let us now check how the trained network classifies the examples in our original sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "UM5LKnbY0eRT",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 0:\n",
      "\tEstimated label: T-shirt\n",
      "\tCorrect label: T-shirt\n",
      "\n",
      "Image 1:\n",
      "\tEstimated label: Dress\n",
      "\tCorrect label: Dress\n",
      "\n",
      "Image 2:\n",
      "\tEstimated label: T-shirt\n",
      "\tCorrect label: T-shirt\n",
      "\n",
      "Image 3:\n",
      "\tEstimated label: Sneaker\n",
      "\tCorrect label: Sneaker\n",
      "\n",
      "Image 4:\n",
      "\tEstimated label: Boot\n",
      "\tCorrect label: Boot\n",
      "\n",
      "Image 5:\n",
      "\tEstimated label: Coat\n",
      "\tCorrect label: Coat\n",
      "\n",
      "Image 6:\n",
      "\tEstimated label: Shirt\n",
      "\tCorrect label: Coat\n",
      "\n",
      "Image 7:\n",
      "\tEstimated label: Shirt\n",
      "\tCorrect label: Shirt\n",
      "\n",
      "Image 8:\n",
      "\tEstimated label: Shirt\n",
      "\tCorrect label: Pull-over\n",
      "\n",
      "Image 9:\n",
      "\tEstimated label: Sandal\n",
      "\tCorrect label: Sandal\n"
     ]
    }
   ],
   "source": [
    "# Run the sample through the network\n",
    "output = net(images.to(device))\n",
    "\n",
    "# Let's check the classification\n",
    "for i in range(output.shape[0]):\n",
    "    y_est = torch.argmax(output[i, :])\n",
    "    y_opt = labels[i]\n",
    "    print('\\nImage %i:' % i)\n",
    "    print('\\tEstimated label:', LABELS[y_est])\n",
    "    print('\\tCorrect label:', LABELS[y_opt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXGtT8v8-L0_"
   },
   "source": [
    "## Evaluate the network\n",
    "\n",
    "We now use the test set that was kept aside to determine the performance of the network on unseen data. We create a simple function that receives a network and a dataset and computes the predictions for that dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "UKQ3X3by9vbF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad() # We don't need gradients for this\n",
    "def get_predictions(network, dataset):\n",
    "\n",
    "    # Create dataloader from dataset\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=10000)\n",
    "\n",
    "    # Create a tensor to store results\n",
    "    predictions = torch.tensor([])\n",
    "    for Xbatch, _ in dataloader:\n",
    "        # Get predictions\n",
    "        output = network(Xbatch.to(device))\n",
    "\n",
    "        # Add them to the tensor\n",
    "        # NOTE: \n",
    "        predictions = torch.cat((predictions, output.cpu()), dim=0)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "undFqeDP-a-s",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "= Confusion matrix in training =\n",
      "[[4739   28   98  317   24    7  713    0   73    1]\n",
      " [   9 5767   32  143   20    1   24    0    4    0]\n",
      " [  42   14 4291   54  960    6  574    0   59    0]\n",
      " [ 180   62   57 5251  244    0  185    0   21    0]\n",
      " [   7    3  332  163 5012    0  452    0   30    1]\n",
      " [   5    0    0    4    0 5578    1  242   38  132]\n",
      " [ 658   19  570  170  666    0 3807    1  108    1]\n",
      " [   0    0    0    0    0  198    0 5534   13  255]\n",
      " [  13    5   24   43   28   33  110   32 5707    5]\n",
      " [   1    1    0    3    0   80    1  214    7 5693]]\n",
      "\n",
      "Training accuracy: 0.8563166666666666\n",
      "\n",
      "= Confusion matrix in test =\n",
      "[[768   4  15  53   7   1 135   0  17   0]\n",
      " [  4 953   4  27   6   0   4   0   2   0]\n",
      " [ 11   4 687  11 177   1  96   0  13   0]\n",
      " [ 21   9  14 863  38   1  50   0   4   0]\n",
      " [  0   1  65  31 807   1  88   0   7   0]\n",
      " [  0   0   0   1   0 910   0  52   4  33]\n",
      " [113   1 106  41 124   1 583   0  31   0]\n",
      " [  0   0   0   0   0  34   0 919   0  47]\n",
      " [  0   1   8   8   4   4  24   6 945   0]\n",
      " [  0   0   0   0   0  13   0  41   1 945]]\n",
      "\n",
      "Test accuracy: 0.838\n"
     ]
    }
   ],
   "source": [
    "# Import function to compute confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# We compute the confusion matrix for the training set\n",
    "predictions = get_predictions(net, train_set)\n",
    "cm_train = confusion_matrix(y_true=train_set.targets, y_pred=predictions.argmax(1))\n",
    "\n",
    "print('\\n= Confusion matrix in training =')\n",
    "print(cm_train)\n",
    "\n",
    "print('\\nTraining accuracy:', cm_train.trace() / predictions.shape[0])\n",
    "\n",
    "# We compute the confusion matrix for the test set\n",
    "predictions = get_predictions(net, test_set)\n",
    "cm_test = confusion_matrix(y_true=test_set.targets, y_pred=predictions.argmax(1))\n",
    "\n",
    "print('\\n= Confusion matrix in test =')\n",
    "print(cm_test)\n",
    "\n",
    "print('\\nTest accuracy:', cm_test.trace() / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x42z0hX-Cr-o"
   },
   "source": [
    "# Activities\n",
    "\n",
    "1. Verify the impact of L2 regularization in the performance of the network. To that purpose, repeat the training of the network, but add to the SGD parameters the option `weight_decay=0.1`.\n",
    "\n",
    "2. Verify the impact of dropout in the performance of the network. To that purpose, repeat the training of the network, but add a dropout layer after the ReLU in the network definition. You can do it by adding the line `nn.Dropout(0.3),` (the number is the dropout probability).\n",
    "\n",
    "3. From your results, do you believe that the original model is overfitting?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOLqefr81L4fh9BHgFjv+d3",
   "collapsed_sections": [],
   "name": "Lab1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
